{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Hedging\n",
    "\n",
    "### Summary \n",
    "\n",
    "Being short volatility hasn't been profitable in this period of extreme implied and realized volatility movements but may be an interesting entry point for some. \n",
    "\n",
    "In this note I take a further look at this strategy and extend it with delta hedging to understand how it can impact performance.\n",
    "\n",
    "Each day I sell a 1m10y straddle (like last time) - but this time I also trade a swap with a matched effective date and termination date to hedge my delta. Each day I unwind the previous day's swap and trade into a new one.\n",
    "\n",
    "I examine premium collected at inception, payout on option expiry and mark-to-market over the life of the trade to compare the two strategies.\n",
    "\n",
    "Look out for future publications where I will build on this analysis further by adding transaction costs and analyzing performance accross strategies.\n",
    "\n",
    "The content of this notebook is split into:\n",
    "* [1 - Let's get started with gs quant](#1---Let's-get-started-with-gs-quant)\n",
    "* [2 - Create portfolio](#2---Create-portfolio)\n",
    "* [3 - Grab the data](#3---Grab-the-data)\n",
    "* [4 - Putting it all together](#4---Putting-it-all-together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Let's get started with gs quant\n",
    "Start every session with authenticating with your unique client id and secret. If you don't have a registered app, create one [here](https://marquee.gs.com/s/developer/myapps/register). `run_analytics` scope is required for the functionality covered in this example. Below produced using gs-quant version 0.8.108."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.session import GsSession\n",
    "GsSession.use(client_id=None, client_secret=None, scopes=('run_analytics',))\n",
    "\n",
    "use_batch = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Create portfolio\n",
    "Just like in our last analysis, let's start by creating a portfolio with a rolling strip of straddles. For each date in our date range (start of 2019 through today), we will construct a 1m10y straddle and include it in our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.markets import HistoricalPricingContext, PricingContext\n",
    "from gs_quant.markets.portfolio import Portfolio\n",
    "from gs_quant.common import Currency, PayReceive\n",
    "from gs_quant.instrument import IRSwaption\n",
    "import datetime as dt\n",
    "\n",
    "start_date = dt.datetime(2020, 12, 1).date()\n",
    "end_date = dt.datetime.today().date()\n",
    "\n",
    "# create and resolve a new straddle on every day of the pricing context\n",
    "with HistoricalPricingContext(start=start_date, end=end_date, show_progress=True): \n",
    "    f = IRSwaption(PayReceive.Straddle, '10y', Currency.USD, expiration_date='1m', \n",
    "                   notional_amount=1e8, buy_sell='Sell').resolve(in_place=False)\n",
    "\n",
    "# put resulting swaptions in a portfolio\n",
    "result = f.result().items()\n",
    "portfolio = Portfolio([v[1] for v in sorted(result)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now convert the portfolio to a dataframe, extend it with trade dates and remove any instruments with a premium payment date after today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = portfolio.to_frame()\n",
    "frame.index = frame.index.droplevel(0)\n",
    "\n",
    "# extend dataframe with trade dates\n",
    "trade_dates = {value:key for key, value in result}\n",
    "frame['trade_date'] = frame.apply(lambda x: trade_dates[x.name], axis=1)\n",
    "\n",
    "# filter any swaptions with premium date larger than today\n",
    "frame = frame[frame.premium_payment_date < dt.datetime.today().date()]\n",
    "frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Grab the Data\n",
    "\n",
    "Now the fun part - we need to calculate a lot of datapoints for this backtest. \n",
    "\n",
    "For each straddle, we need to define a new swap every day and price it the following day when we unwind it. This means about 36,000 points (~300 instruments * 30 days * 4 measures (swaption price, swaption delta, swap price, swap delta)).\n",
    "\n",
    "Like last time I will compute as much as I can asyncrously and keep track of the futures for each measure. \n",
    "\n",
    "Introducing a high-level `PricingContext` to batch requests can improve speed as well. Note just using `PricingContext` will improve speed but `batch=True` can  add efficiency.\n",
    "\n",
    "To learn more about async and other compute controls and how to use them, please see our [pricing context guide](https://developer.gs.com/docs/gsquant/guides/Pricing-and-Risk/pricing-context/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by getting the prices and delta for the swaptions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.risk import IRDeltaParallel\n",
    "\n",
    "# insert columns in our frame to track the futures\n",
    "frame['so_price_f'] = len(frame) * [None]\n",
    "frame['so_delta_f'] = len(frame) * [None]\n",
    "\n",
    "with PricingContext(is_batch=use_batch, show_progress=True):\n",
    "    for inst, row in frame.iterrows():\n",
    "        with HistoricalPricingContext(start=row.trade_date, \n",
    "                                      end=min(row.expiration_date, dt.datetime.today().date()), \n",
    "                                      is_async=True):\n",
    "            so_price = inst.price()\n",
    "            so_delta = inst.calc(IRDeltaParallel)        \n",
    "\n",
    "        frame.at[inst, 'so_price_f'] = so_price\n",
    "        frame.at[inst, 'so_delta_f'] = so_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy enough. I will now do the same for the swaps which I will use to delta hedge. Note instead of pricing the same already resolved swaption each day, here I create and price a new swap each day which will reflect that's day's ATM rate and matches the effective date and termination date of the corresponding swaption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.instrument import IRSwap\n",
    "\n",
    "# insert columns in our frame to track the futures\n",
    "frame['s_f'] = len(frame) * [None]\n",
    "frame['s_delta_f'] = len(frame) * [None]\n",
    "\n",
    "with PricingContext(is_batch=use_batch, show_progress=True):\n",
    "    for inst, row in frame.iterrows():\n",
    "        swap = IRSwap(PayReceive.Pay, row.termination_date, Currency.USD, \n",
    "                      effective_date=row.effective_date, fixed_rate='ATMF', notional_amount=1e8)\n",
    "\n",
    "        with HistoricalPricingContext(start=row.trade_date, \n",
    "                                      end=min(row.expiration_date, dt.datetime.today().date()), \n",
    "                                      is_async=True):\n",
    "            # track the resolved swap - we will need to price it when we unwind following day\n",
    "            s = swap.resolve(in_place=False)\n",
    "            s_delta = swap.calc(IRDeltaParallel)\n",
    "\n",
    "        frame.at[inst, 's_f'] = s\n",
    "        frame.at[inst, 's_delta_f'] = s_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above request, we created a new resolved swaption for each day but we still need to price it the following day when we unwind it. In the below, I collect the resolved swaps from the previous request and price lagged 1 day - that is, the following day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.markets import PricingContext\n",
    "import pandas as pd\n",
    "\n",
    "swaps = pd.concat([pd.Series(row.s_f.result(), name=row.name) for _, row in frame.iterrows()], \n",
    "                      axis=1, sort=True).shift(periods=1)\n",
    "g = {}\n",
    "\n",
    "with PricingContext(is_batch=use_batch, show_progress=True):\n",
    "    for date, row in swaps.iterrows():\n",
    "        with PricingContext(date, is_async=True):\n",
    "            prices = {k: p if isinstance(p, float) else p.price() for k, p in row.iteritems()}\n",
    "        g[date] = prices\n",
    "        \n",
    "swap_prices = pd.DataFrame(g).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's collect all the points and do some arithmetic to create a timeseries for each swaption. I will create two frames - one for the simple vol selling strategy and one taking into account the changing delta hedge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.timeseries import *\n",
    "\n",
    "not_delta_hedged = []\n",
    "delta_hedged = []\n",
    "\n",
    "for inst, row in frame.iterrows():\n",
    "    # collect all the results\n",
    "    total_result = pd.concat([row.so_price_f.result(), row.so_delta_f.result(), \n",
    "                              pd.Series({k: v.result() for k, v in swap_prices[inst].iteritems() \n",
    "                                         if not isinstance(v, float)}), \n",
    "                              row.s_delta_f.result()], axis=1, sort=True)\n",
    "    total_result.columns = ['swaption_prices', 'swaption_delta', 'swap_bought_prices', 'swap_sold_delta']\n",
    "    \n",
    "    # today's hedge notional will be the ratio of prior day's swaption/swap delta ratio - that's\n",
    "    # how much of the swap we bought to hedge so will use it to scale unwind PV of the swap today\n",
    "    total_result['hedge_notional'] = -(total_result.swaption_delta/total_result.swap_sold_delta).shift(periods=1)\n",
    "    total_result = total_result.fillna(0)\n",
    "    \n",
    "    # scale the umwind PV of prior day's swap hedge\n",
    "    total_result['swap_pos'] = total_result['hedge_notional'] * total_result['swap_bought_prices']\n",
    "    \n",
    "    # add to swaption price to get total performance cutting off last time due to the lag\n",
    "    swaption_pl = diff(total_result['swaption_prices'], 1).fillna(0)\n",
    "    total_result['total_pv'] = swaption_pl + total_result['swap_pos']\n",
    "    \n",
    "    not_delta_hedged.append(pd.Series(swaption_pl[:-1], name=inst))\n",
    "    delta_hedged.append(pd.Series(total_result['total_pv'][:-1], name=inst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Putting it all together\n",
    "Now, let's combine all the results to look at the impact delta hedging makes on the strategy. Unsurprisingly, the delta hedged version provides protection to tail events like March 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_dh = pd.concat(not_delta_hedged, axis=1, sort=True).fillna(0).sum(axis=1).cumsum()\n",
    "dh = pd.concat(delta_hedged, axis=1, sort=True).fillna(0).sum(axis=1).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame([dh, not_dh]).T\n",
    "comp.columns = ['Delta Hedged', 'Not Delta Hedged']\n",
    "comp.plot(figsize=(10, 6), title='Hedged vs Not Hedged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this backtesting doesn't include transaction costs and the implementation is different from how one might hedge in practice (unwinding and trading a new swap every day) but is economically equivalent to layering the hedges (and is cleaner from a calculation perspective).\n",
    "\n",
    "Look out for future publications for added transaction costs and ways to quantitatively compare these strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Backtesting Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gs_quant.backtests.triggers import PeriodicTrigger, PeriodicTriggerRequirements\n",
    "from gs_quant.backtests.actions import AddTradeAction, HedgeAction\n",
    "from gs_quant.backtests.generic_engine import GenericEngine\n",
    "from gs_quant.backtests.strategy import Strategy\n",
    "from gs_quant.common import AggregationLevel\n",
    "from gs_quant.risk import IRDelta, Price\n",
    "\n",
    "# dates on which actions will be triggered\n",
    "trig_req = PeriodicTriggerRequirements(start_date=start_date, end_date=end_date, frequency='1b')\n",
    "\n",
    "# instrument that will be added on AddTradeAction\n",
    "irswaption = IRSwaption('Straddle', '10y', 'USD', expiration_date='1m', notional_amount=1e8,\n",
    "                        buy_sell='Sell', name='1m10y')\n",
    "swap_hedge = IRSwap(PayReceive.Pay, '10y', 'USD', fixed_rate='ATMF', notional_amount=1e8, name='10y_swap')\n",
    "action_trade = AddTradeAction(irswaption, 'expiration_date')\n",
    "action_hedge = HedgeAction(IRDelta(aggregation_level=AggregationLevel.Type, currency='local'), swap_hedge, '1b')\n",
    "\n",
    "# starting with empty portfolio (first arg to Strategy), apply actions on trig_req\n",
    "triggers = PeriodicTrigger(trig_req, [action_trade, action_hedge])\n",
    "strategy = Strategy(None, triggers)\n",
    "\n",
    "# run backtest\n",
    "GE = GenericEngine()\n",
    "backtest = GE.run_backtest(strategy, start=start_date, end=end_date, frequency='1b', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, these strategies won't be exactly the same since the original series. This is because the original series is matching each swaption with a swap and holding both positions while resizing the swap each day. In the generic backtester snippet above, we passed '1b' for hedge holding period. This means that the delta from ALL swaption positions on a given date will be hedged with a single swap which will be replaced each day. Note if instead of '1b', we put '10y' for example (to match swaption tail), the swap hedge will be 'layered' - that is, we will add positive or negative notional each day but not unwind the existing swap hedges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Generic backtester': backtest.result_summary['Cash'].cumsum() + backtest.result_summary[Price],\n",
    "              'Original series': dh}).plot(figsize=(10, 6), title='Delta hedged backtest comparison')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}